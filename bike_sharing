import numpy as np
import pandas as pd

# import data
train = pd.read_csv("...train.csv", parse_dates = ["datetime"])
test = pd.read_csv(".../test.csv", parse_dates = ["datetime"])

# Split "datetime"
train["year"] = train["datetime"].dt.year
train["hour"] = train["datetime"].dt.hour
train["dayofweek"] = train["datetime"].dt.dayofweek

test["year"] = test["datetime"].dt.year
test["hour"] = test["datetime"].dt.hour
test["dayofweek"] = test["datetime"].dt.dayofweek

# Analysis data
import seaborn as sns
import matplotlib.pyplot as plt

# let's see the big trend by year-month
train["datetime-year(str)"] = train["datetime-year"].astype('str')
train["datetime-month(str)"] = train["datetime-month"].astype('str')
train["datetime-year_month"] = train["datetime-year(str)"] + "-" + train["datetime-month(str)"]
sns.barplot(data=train, x="datetime-year_month", y="count")

# analysis by hour
sns.pointplot(data=train, x="datetime-hour", y="count")

# analysis by day
sns.pointplot(data=train, x="datetime-hour", y="count", hue="workingday")

# Preprocessing
train.drop(["datetime", "windspeed", "casual", "registered", "count"], 1, inplace=True)
test.drop(["datetime", "windspeed"], 1, inplace=True)

y_train = train["count"]
y_train = np.log1p(y_train) # to look like normal distribution

# Prepare for prediction
from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor(n_estimators=100)

# fit, predict
rf.fit(train,y_train)
preds = rf.predict(test)

# submit
submission = pd.read_csv(".../sampleSubmission.csv")
submission["count"] = np.expm1(preds) # lift log
submission.to_csv("prediction_submission.csv", index=False)
